Construire des outils d’évaluation de l’efficacité d’un dispositif pédagogique à distance : le cas de l’efficacité interne d’IFADEM RDC/Katanga.
Introduction Les restrictions budgétaires, la concurrence des différents offreurs de formations, le processus de Bologne sont au moins trois des causes du développement des évaluations des formations. Parmi les fondamentaux du processus de Bologne, on retrouve l’exigence de « la qualité de l’enseignement ». L’Organisation des Nations Unies pour l’éducation, la science et la culture (UNESCO), stipule en 1998 que « la qualité concerne toutes les fonctions et activités de l’enseignement supérieur : enseignement et programme, recherche, étudiants, dotations, équipements ». De plus, pour cet organisme, l’évaluation est nécessaire dans l’amélioration de la qualité. Ainsi, « parler d’évaluation de l’enseignement supérieur revient à en améliorer la qualité, par une évaluation interne, et un examen externe par des experts indépendants ». Parler de qualité revient donc aussi à parler d’évaluation, ce qui, selon Barbier (1985) cité par Gangloff et al. (2010) est considéré comme un acte délibéré et socialement organisé aboutissant à la production d’un jugement de valeur. Romainville (2009) explique ainsi que l’évaluation est aussi un moyen de se situer, elle permet de mesurer la réalité des acquisitions, autant pour l’enseignant que pour les étudiants. L’Agence universitaire de la francophonie (AUF) et l’Organisation internationale de la francophonie (OIF) créent en 2007 l’Initiative francophone pour la formation à distance des maîtres (IFADEM) qui « participe aux efforts internationaux en faveur d’une Éducation de base de qualité ». En partenariat avec l’IFADEM, les pays engagés dans sa mise en œuvre – actuellement le Bénin, le Burundi, Haïti, le Liban, Madagascar, le Niger et la République démocratique du Congo – conçoivent et organisent un dispositif de formation des maîtres en partie à distance, adapté aux besoins de leurs systèmes éducatifs et utilisant les technologies de l’information et de la communication (TIC). Ainsi, l’objet de cette contribution est double :  estimer l’efficacité d’IFADEM, en termes d’atteinte des objectifs de l’institution (ici l’AUF et l’OIF), quant à l’acquisition de compétences pédagogiques et du savoir en français ; estimer l’efficacité du dispositif d’évaluation par le biais d’un sondage sur les pratiques professionnelles et une observation. Contexte théorique : la problématique de la mesure de l’efficacité des dispositifs pédagogiques Dans le champ pédagogique, Charlier (2000) rappelle que « le terme de “dispositif” est souvent utilisé de façon banale pour désigner un ensemble de moyens organisés, définis et stables qui sont le cadre d’actions réitérables conduites pour répondre à un problème récurrent » (Paquelin, 2009, p. 156). Les dispositifs seraient des moyens mis en place pour répondre à un problème. Un dispositif pédagogique à distance est généralement caractérisé par la séparation ou l’éloignement physique de l’enseignant et de l’enseigné lors des enseignements (Rumble, 1997 ; Ben Abid, 2000), ce qui n’empêche pas des séances de regroupements.  On sait cependant que le terme d’« enseignement à distance » est beaucoup plus complexe à définir. Selon Glickman (2002), en France, le terme d’enseignement à distance est de moins en moins utilisé par les chercheurs et on lui préfère celui de « formation à distance ». En effet, cette dernière dénomination suppose que l’on cherche à prendre en compte à la fois l’enseignement à distance mais aussi l’apprentissage à distance dans un but d’analyse du processus qui y mène. Cependant, comme nous nous intéressons ici à l’effet du dispositif sur l’amélioration des compétences, sans nous intéresser à la manière dont l’usager utilise le dispositif, nous utiliserons le terme d’« enseignement à distance ». Mesurer l’efficacité d’un dispositif est très peu aisé, ne serait-ce que parce que tout le monde n’en donne pas la même définition. Eicher (1983) l’exprimait déjà ainsi à propos de l’efficacité des modes d’enseignement à distance : « de façon large, on pourrait peut-être faire l’hypothèse qu’un système d’enseignement à distance est plus efficace qu’un système traditionnel s’il rend ses usagers plus heureux. Mais la mesure du bonheur pose des problèmes que l’économiste hésite à aborder… » (Ben Abid, 2000, p. 51). Selon lui – comme l’estimation de l’efficacité était fonction de celui qui la mesurait –, cette efficacité peut être très large, parce que très souvent on fait le choix de circonscrire son estimation par commodité de mesure et que tout dispositif a un objectif qui lui est assigné et qui doit être atteint. En effet, Chomienne (1999) explique qu’« estimer l’efficacité » signifie examiner dans quelle mesure les objectifs prévus par un « processus » sont atteints.  Ben Abid-Zarrouk (2013) distingue deux types d’efficacité : l’efficacité institutionnelle et l’efficacité individuelle. L’efficacité individuelle d’un dispositif suppose de mettre l’usager au centre du dispositif. L’auteure après une brève revue de la littérature sur le dispositif a été amenée à considérer que le passage d’un dispositif objectif à un dispositif subjectif supposait de mettre en avant l’usager et de le rendre acteur de l’atteinte de l’objectif qu’il s’est donné. L’auteure montre qu’en fonction d’un certain nombre de facteurs exogènes au dispositif, comme l’information dont il dispose sur le dispositif, les stratégies des apprentissages de l’usager, l’utilisation optimale du dispositif et enfin la satisfaction qu’il en retire, influe sur l’atteinte de ses propres objectifs. L’efficacité institutionnelle d’un dispositif, quant à elle, est l’efficacité qui intéresse le concepteur, le décideur politique ou le maître d’ouvrage d’un dispositif donné, dans le but d’atteindre un objectif donné, décidé par lui. Son évaluation suppose d’examiner dans quelle mesure les objectifs d’un dispositif sont atteints. La particularité de l’efficacité institutionnelle est de ne s’intéresser qu’à l’effet d’un dispositif donné (conçu généralement par l’institution) sur des objectifs désignés par l’institution. Elle se caractérise aussi par le fait qu’elle responsabilise le dispositif et non l’usager sur l’atteinte ou non de ces objectifs. Elle est estimée à partir de cinq indicateurs : 1 - l’efficacité interne, mesurée traditionnellement par les taux de réussite ou des résultats à des tests de connaissances ; 2 - l’efficacité externe qui fait le lien entre le diplôme et/ou la formation et l’insertion sur le marché du travail ; 3 - l’équité qui est mesurée dans la majorité des cas par l’estimation de l’accès et de la réussite d’un sous-groupe par rapport à un groupe total ; 4 - l’efficience qui compare l’effort financier (ex : coût unitaire) par rapport aux effets attendus (ex : taux de réussite) ; 5 - la qualité de la formation et des enseignements estimée à partir de la satisfaction des usagers.  L’AUF a décidé d’évaluer le dispositif IFADEM afin de mesurer les effets de ce dernier sur l’évolution des compétences des instituteurs katangais. Nous nous situons donc bien dans ce que Ben Abid-Zarrouk appelle (2013) l’efficacité institutionnelle. Plus précisément, comme cet organisme s’intéresse à l’effet de la formation sur des compétences, nous aurons pour indicateur l’efficacité interne. En effet, lorsque l’on étudie l’apport d’un dispositif pédagogique sur l’amélioration de l’apprentissage, l’évolution des connaissances ou des compétences, on mesure l’efficacité interne. Cet indicateur est généralement estimé à partir de tests de connaissances (Eicher, 1983) et il est apprécié « en fonction de l’amélioration des résultats scolaires des élèves » (Chaptal, 2009).  Dans le cadre de l’évaluation du dispositif IFADEM, l’AUF a proposé deux outils d’évaluation avant et après la formation : un questionnaire intitulé « Sondage sur les pratiques professionnelles des enseignants », et une grille d’observation. Nous proposons pour cette contribution d’estimer l’efficacité du dispositif IFADEM dans un premier temps puis d’estimer l’efficacité des outils d’évaluation de la formation. Méthodologie  Dans cette section, nous reprenons les principaux éléments qui caractérisent la formation IFADEM.  L’initiative francophone pour la formation à distance des maîtres (IFADEM) Lancée en 2007 par l’Agence universitaire de la francophonie et l’Organisation internationale de la francophonie, l’Initiative francophone pour la formation à distance des maîtres participe aux efforts internationaux en faveur d’une Éducation de base de qualité. En partenariat avec IFADEM, les pays engagés dans sa mise en œuvre – actuellement le Bénin, le Burundi, la Côte d’Ivoire, Haïti, le Liban, Madagascar, le Niger et la RDC – conçoivent et organisent un dispositif de formation des maîtres adapté aux besoins de leurs systèmes éducatifs, en partie à distance et utilisant les technologies de l’information et de la communication. Le principe est une formation hybride alternant regroupements en présentiel et travail à distance. Les outils de formation sont créés dans chaque pays par une équipe de concepteurs nationaux soutenue par des experts techniques issus d’universités francophones. Les contenus pédagogiques tiennent compte des spécificités éducatives, socioculturelles et sociolinguistiques des pays. Ces supports (livrets pédagogiques, accompagnés pour certains de ressources audio écoutables et/ou téléchargeables) sont consultables sur le site Internet et sur la plateforme d’enseignement à distance Moodle. En parallèle, des ateliers de formation sont également proposés. Il s’agit notamment d’initiations : à l’informatique et Internet ; au tutorat à distance ; à la formation ouverte et à distance. Créés pour les concepteurs de contenus, les tuteurs, les instituteurs mais aussi les élèves instituteurs, ces ateliers s’adjoignent au parcours de formation IFADEM dans le but de répondre aux demandes croissantes de formations spécialisées en technologies éducatives. « Les contenus des ateliers sont élaborés en tenant compte du public visé, du parcours de formation et des perspectives de déploiement de l’ensemble du dispositif IFADEM. » Pour finir, des ressources conseillées sont mises en ligne sur le site Thot Cursus. Ce dernier répertorie et classe les articles et ressources éducatives qu’il publie chaque semaine. Trois domaines sont représentés : les ressources pédagogiques pour le primaire, la formation initiale et continue des maîtres, et les TICE et la FOAD au primaire. Par conséquent, « les enseignants et formateurs impliqués dans le programme de formation IFADEM, mais aussi tous les acteurs des systèmes éducatifs investis dans l’éducation de base, peuvent ainsi facilement disposer de références exploitables dans leur contexte professionnel. » Entre 2011 et 2013, IFADEM est expérimentée par le Ministère de l’Enseignement primaire, secondaire et professionnel (MEPSP) dans la province du Katanga, avec l’appui de l’Agence pour la promotion de l’enseignement et de la formation à l’étranger (APEFE). Pour cette phase de formation, IFADEM-RDC/Katanga cible des institutrices et instituteurs des sous-provinces de Likasi et de Kolwezi, en poste dans des classes du 3e degré (5e et 6e années). Au total, 580 enseignants suivent un programme de formation de 282 heures dont 42 en présentiel étalées sur neuf mois. Plusieurs regroupements permettent aux instituteurs et institutrices de rencontrer leurs tuteurs avec trois visées : d’abord expliquer comment utiliser les livrets de formation. En effet, six livrets de formation sont proposés portant sur la linguistique et la didactique, plus particulièrement sur les aspects de la linguistique française et les aspects méthodologiques de la didactique du français ; ensuite aider les enseignants en cas de difficultés d’appropriation des outils ; enfin proposer aux enseignants des méthodologies d’apprentissage des livrets et d’enseignement dans les classes. Bref rappel de la construction de l’outil d’évaluation  À la suite d’un séminaire en juin 2013 qui avait pour but la conception d’un cahier des charges pour la conception d’un outil de mesure des compétences professionnelles des enseignants (tests entrée/sortie), une équipe composée d’experts techniques internationaux IFADEM et de concepteurs de livrets burundais et malgaches a travaillé sur un questionnaire d’évaluation. Le questionnaire a ensuite été retravaillé par les chefs de projets IFADEM ainsi que le coordinateur du groupe d’experts. Ce premier questionnaire a été appelé « sondage des pratiques professionnelles » (joint en annexe de cet article). Un second outil plutôt de type qualitatif celui-là est basé sur l’observation des pratiques professionnelles des enseignants par des tuteurs. Ces derniers étant très souvent des inspecteurs. Les compétences évaluées dans les deux questionnaires Les compétences évaluées sont fonction du contenu des différents livrets utilisés pour la formation des instituteurs. Il s’agit de : tenir compte des interférences linguistiques et culturelles ; repérer les erreurs phonétiques et grammaticales et y remédier (Livret 1) ; développer les compétences de compréhension et production orales : vocabulaire, grammaire, expression (Livret 2) ; développer les compétences de compréhension et production écrites : vocabulaire, grammaire, texte (Livret 3) ; organiser le travail en classe : les séquences, les interactions, la gestion des grands groupes (Livret 4) ; enseigner les mathématiques en français (Livret 5) ; enseigner les disciplines d’éveil scientifique en français (Livret 6). Précisons que chaque livret est construit à partir d’une étude préalable des besoins des enseignants. Celle-ci permet de construire des programmes adaptés aux réalités nationales, tout en proposant une architecture et des principes didactiques communs aux pays. L’IFADEM lutte avant tout pour l’intégration et la valorisation des compétences des instituteurs : « [L’IFADEM] part donc d’une interrogation sur les pratiques de classe des enseignants, on apporte des connaissances nécessaires qu’on intègre, dans des activités variées, à des savoir-faire spécifiques, et enfin on propose une remédiation à expérimenter dans la classe. » Les variables étudiées dans les questionnaires Les variables prises en compte dans les deux questionnaires d’évaluation concernaient les caractéristiques socioprofessionnelles : le diplôme, classe d’enseignement, ancienneté dans l’enseignement dans le premier ; sexe, âge, diplôme, ancienneté dans l’enseignement et ancienneté en tant que fonctionnaire dans le second. Les questionnaires proposaient 25 questions soit 47 items parmi les catégories suivantes : attitudes efficaces à posséder par l’enseignant pour un meilleur enseignement du français, attitude des enseignants face au travail en groupe, les étapes logiques d’une leçon de compréhension orale et d’une leçon de correction phonétique, compétences pédagogiques de l’enseignant en général et celles liées à l’apprentissage du français en particulier, attitudes « professionnelles » générales des enseignants avec les parents et les élèves en dehors de la classe.  Méthodes d’analyse des données quantitatives Pour estimer l’efficacité du dispositif de formation IFADEM, nous avons effectué une analyse descriptive. En effet, nous avons analysé la proportion de « bonnes », de « mauvaises » et de « non-réponses » entre le test d’entrée (QE) et le même à la sortie (QS) dans le but de constater ou non, une évolution. Nous faisons l’hypothèse que les non-réponses sont le résultat d’une non-compréhension de la question soit par manque de connaissances sur le sujet, soit parce que la formulation de la question ou de la proposition du questionnaire ne permet pas d’y répondre. Ainsi, si l’on constate qu’entre l’avant-formation et l’après-formation la proportion de non-réponses a diminué, alors on estimera que la non-réponse au début du test était liée à une absence de connaissances (estimées en termes de savoir) sur le sujet. Si au contraire cette proportion n’a pas évolué ou disparu, on questionnera alors la formulation de la question. Afin d’estimer l’efficacité du dispositif de formation IFADEM, nous avons également procédé à une analyse multivariée. Pour cela nous avons étudié les variables socioprofessionnelles qui influent sur le fait de répondre positivement aux différentes questions du sondage après la formation à partir des modèles de régression logistique.  Présentation générale de l’outil qualitatif La grille d’observation des pratiques professionnelles des instituteurs est constituée de trois grandes parties ; profil professionnel de l’enseignant, pratiques de classe, synthèse. Les questions portant sur les pratiques de classe sont réparties en six rubriques : structurer son enseignement ; rôle/positionnement de l’enseignant ; prise de conscience du bi/multilinguisme et des caractéristiques du français local ; démarche didactique pour l’enseignement du français ; pratique de la correction et de l’évaluation ; compétences linguistiques en contexte professionnel. L’évaluateur dispose d’une page pour apporter son ressenti (remarques et suggestions) quant à la forme et le contenu de l’outil.  Méthodes d’analyse des données qualitatives À l’entrée, c’est-à-dire avant la formation IFADEM, dix-sept enseignants ont été observés par des inspecteurs durant une séance d’enseignement tandis qu’à la sortie (c’est-à-dire à la suite des neuf mois de formation) seuls huit enseignants ont été évalués.  Par conséquent, nous avons tout d’abord tenté, à travers ces séances d’observation, de reconstituer des caractéristiques « types » de leur mode d’enseignement avant la formation et après la formation. Puis, dans un second temps, nous avons cherché à repérer une évolution des pratiques enseignantes entre le début et la sortie de la formation.  Méthodes d’analyse mixte Ce que nous avons appelé analyse mixte, c’est la combinaison des résultats des données qualitatives et des données quantitatives. Nous avons ainsi comparé les réponses au sondage aux observations effectuées par les inspecteurs.  Résultats de l’enquête L’analyse quantitative  Le public À l’entrée : 145 enseignants ont participé au sondage, 51,1 % enseignent en classe de 5e et 48,3 % en classe de 6e et 0,7 % n’enseigne dans aucune classe. En moyenne ils enseignent depuis 18,37 années. La médiane se situant à 17 ans.  À la sortie : 129 enseignants : 68,2 % de femmes et 27,9 % d’hommes, âge : 43,5 ans, ancienneté 19,2 ans. En moyenne, ils sont fonctionnaires depuis 15,2 ans. Ils sont titulaires d’un diplôme D6 pour 62 % d’entre eux, 15 % ont un D4 et 23 % déclarent avoir un autre diplôme. Résultats de l’analyse descriptive L’analyse descriptive porte sur vingt-cinq questions et fait apparaître une évolution positive et négative. Le tableau ci-après synthétise les taux d’évolution pour chacune des questions. Ils ont été calculés à partir des réponses données à l’entrée en formation puis à la sortie.  1.2.1 Analyse : influence de la formation sur les compétences déclarées par les enseignants  Les compétences que tentent d’évaluer les cinq premières questions du questionnaire, et relatives aux attitudes efficaces à adopter pour un meilleur enseignement du et en français, semblent, pour certaines, maîtrisées à la fin de la formation (Q2, Q3 et Q5). On constatera cependant que parmi ce groupe de questions deux ont connu des baisses de réponses considérées comme « justes ». C’est le cas de la question 5, les enseignants, en début de formation étaient 75 % à répondre que lorsqu’ils sont en classe de français (ou de sciences en français), ils n’acceptent pas que les élèves utilisent des expressions propres au langage oral (par exemple « y’a » au lieu de « il y a »), à la fin de la formation ils étaient plus de 80 %. Ce qui est considéré comme étant une « mauvaise » réponse. La question 1 a connu la même évolution, les enseignants étaient près de 6 enseignants sur 10 à considérer qu’en classe de français, il est « inadmissible » (ce qui est considéré comme étant une « mauvaise » réponse) que leurs élèves « utilisent souvent leur langue maternelle », ils sont plus de 80 % en fin de formation.  S’agissant de la question 7, relatives aux regards que portent les enseignants sur le travail de groupe, on constate une évolution positive. Ceci qui nous permet d’affirmer que les enseignants ont changé d’attitude, à la suite de la formation, concernant l’importance du travail en groupe et son influence positive sur l’apprentissage des élèves. Cette tendance est confirmée par la question 8. On notera cependant une évolution négative pour la question 8E, (-73 %). En effet, à la suite de la formation, les enseignants considèrent que le travail en petit groupe a pour but de mieux surveiller les élèves, ce qui est considéré comme une mauvaise réponse.  Parmi les questions relatives à l’enseignement oral et son rôle dans l’apprentissage d’une langue (questions 9 et 10), malgré une réelle évolution « positive », un pourcentage très faible des enseignants est concerné. C’est la question n° 10 qui semble poser le plus de problèmes. En effet, seuls 14 % des enseignants ont donné une réponse considérée comme « bonne » à la fin de la formation. En très grande majorité, ils ne savent pas identifier les différentes étapes qui permettent de remédier aux erreurs phonétiques systématiques, faites par les élèves. On notera aussi, malgré une croissance de 140 % par rapport au début de formation, que plus de 70 % des enseignants ne savent pas, à la fin de la formation, identifier les différentes démarches successives qui permettent la compréhension d’un document oral (Q9). On notera aussi que les enseignants sont quasiment autant entre le début et à la fin de la formation (80 % à 82 %) à considérer que dans l’enseignement/apprentissage d’une langue, la compréhension orale (l’écoute) doit avoir une place de choix (Q12), ce qui est considéré comme étant une « bonne réponse ».  La question 13, relative à la suppression des séances d’expression orale si les élèves commettent beaucoup trop de fautes de fond et de forme dans la rédaction. Les enseignants sont proportionnellement plus nombreux à comprendre l’importance de l’oral dans l’apprentissage de la langue. En effet, on constate une évolution de 25 %, entre le début et la fin de la formation.  À la question 14, malgré une évolution « positive » de 25 %, entre le début et la fin de la formation, plus de 60 % des enseignants n’ont pas donné la « bonne » réponse, ils continuent dans leur très grande majorité à ne pas faire la distinction entre apprentissage et enseignement, soit à supposer que le mot « apprendre » n’a pas sa place.  S’agissant des questions 17 et 15, relatives à la remédiation à l’écrit, on constate une réelle évolution des pratiques des enseignants. Ainsi, la proportion de « bonnes » réponses a respectivement évolué de + 25 % et + 36 % entre le début et la fin de la formation.  S’agissant des questions 16, il semble, que hormis les sous-questions 16c (+ 36 %) et 16a (9,5 %), les enseignants ne paraissent pas maîtriser la remédiation orale à la fin de la formation. On constate même une chute des proportions de « bonnes » réponses pour la majorité des sous-questions 16 (16b : - 35 % ; 16e : - 17 % ; 16d : - 77 %).  S’agissant de la question Q18, relative à la remédiation orale, on constate une réelle évolution « positive » des pratiques des enseignants, selon leurs déclarations, entre le début et à la fin de la formation.  S’agissant de la question 19, à la fin de la formation, entre sept et huit enseignants sur dix savent distinguer les différentes formes d’évaluation (diagnostique, sommative et formative), ils n’étaient qu’à peine plus de quatre enseignants sur dix avant la formation. De même à la fin de la formation, ils déclarent à 70 % qu’ils utilisent les trois formes d’évaluation, ils étaient moins de la moitié à la fin de la formation (Q20).  S’agissant de la question 21, relatives aux supports pédagogiques et à leur utilisation efficace par les enseignants, on constate une évolution significative, entre le début et la fin de la formation. Ainsi, les enseignants, au vu de leurs réponses, semblent utiliser de manière de plus en plus efficace les supports pédagogiques et en comprennent l’utilité.  Enfin, à la fin de la formation, les instituteurs déclarent quasi unanimement maîtriser les compétences relatives aux rapports à entretenir avec les parents d’élèves, les collègues et les élèves hors situation de classes (Q21, Q22, Q23).  1.2.2 Récapitulatif  Une évolution positive : 40 questions sur 47, soit 85,1 %, ont vu une hausse des réponses positives. Citons Q7b (+ 70 %), Q9 (+ 140 %), Q18a (+ 114 %), Q18b (+ 92 %), Q19a (+ 95,8 %), Q19b (+ 73 %), Q19c (+ 98 %), Q21b (+ 78,8 %), Q21c (+ 58,8 %). Une évolution négative : seules 7 questions sur 47, soit 15 %, ont vu une baisse des réponses positives. Citons Q1 (- 44 %), Q5 (- 23 %), Q8e (- 73 %), Q11c (- 18 %), Q16b (- 35 %), Q16d (- 77 %), Q16e (- 17 %). Tableau 1 : Taux d’évolution des réponses "positives" à l’entrée et à la sortie de la formation   Au vu de leurs déclarations, les enseignants ont progressé. Ils savent désormais :  formuler des remédiations orales et écrites ; &lt;#ITALIQUES#&gt;&lt;/#ITALIQUES#&gt;accomplir les étapes qui permettent de corriger les erreurs phonétiques ; effectuer les démarches qui favorisent la compréhension d’un support oral ; énoncer le rôle du travail en groupe et le mettre en œuvre ;  distinguer l’enseignement de l’apprentissage ; identifier les différentes formes d’évaluation (sommative, diagnostique et formative) et les appliquer en classe.  La baisse des taux de « bonnes » réponses s’explique par une vision « extrémiste » de l’apprentissage des langues. En effet, les enseignants restent partisans de la méthode d’apprentissage par « immersion » qui n’autorise ni les approximations ni l’usage de la langue maternelle en classe. Les résultats de l’analyse multivariée à la sortie Nous avons construit autant de modèles de régression que de questions posées afin d’identifier la corrélation existant entre les variables suivantes et le fait de donner une « bonne » réponse. À la suite de ces modèles, seules dix questions semblent être fonction de certaines caractéristiques d’enseignants. Les variables année d’ancienneté, sexe et diplôme sont celles qui semblent influer sur les questions 2, 4, 7b, 7e, 8a, 8b, 14, 15, 16a et 25. La variable année d’ancienneté L’ancienneté dans l’enseignement semble, aussi, jouer un rôle pour :  La Q7b, relative au fait que le travail en groupe peut aussi être efficace pour l’enseignement ou l’apprentissage en langue. La Q14 relative à la distinction et la définition de l’enseignement et de l’apprentissage. La Q15 relative aux méthodes de correction du mot « soixante ». La variable sexe Les institutrices auraient plus souvent tendance à donner une « bonne » réponse par rapport aux instituteurs pour les questions suivantes :  Malgré le nombre d’élèves dans une classe, on peut les faire travailler en groupe (Q7e). Faire travailler les élèves en groupe a pour but qu’ils s’aident mutuellement (Q8a). Faire travailler les élèves en groupe permet à plus d’élèves de s’exprimer en français (8b). À la suite d’une attitude déplacée d’un élève « garçon » envers une élève « fille » les enseignantes auraient plus souvent une attitude jugée « bonne » comparativement à leurs homologues masculins. La variable diplôme Les enseignants diplômés D6 adopteraient une « bonne » attitude face au comportement déplacé d’un garçon envers une fille comparativement aux enseignants ayant d’autres diplômes (Q25). Les enseignants diplômés D6 adopteraient une « bonne » attitude quand un élève éprouve des difficultés pour formuler en français une réponse à la suite de la lecture d’un texte comparativement aux enseignants ayant d’autres diplômes (Q16a). Les enseignants ayant un diplôme D6 auraient une « bonne » attitude, face à un élève, qui emploierait une expression qui ne s’utilise que dans le pays d’origine comparativement aux enseignants ayant d’autres diplômes (Q4).  Tableau n° 2 : Récapitulatif des variables influençant les "bonnes" réponses  La formation semble avoir joué un rôle significatif dans les résultats aux tests d’évaluation. En effet, la proportion de réponses cataloguées comme « bonnes » a, dans l’ensemble, augmenté de 38 % par rapport au début de la formation. On notera cependant que certaines questions ont connu soit des baisses de leur proportion de bonnes réponses (Q8E, Q11c, Q16b, Q16d, 16e) entre le début et la fin de la formation, soit des augmentations très peu significatives (Q10, Q14, Q16a).  Les modèles de régression logistique ont permis de montrer que certaines caractéristiques intrinsèques (sexe) et/ou extrinsèques (diplôme et ancienneté dans l’enseignement) pouvaient influer sur le fait de donner une « bonne » réponse à certaines questions. L’analyse qualitative : résultats des observations À l’entrée, les observations ont porté sur dix-sept enseignants alors qu’à la sortie, les observations ont porté sur huit enseignants.  Le tableau 3 récapitule les caractéristiques de ces deux échantillons et montre notamment que l’avis des inspecteurs quant au niveau de la classe a évolué positivement. En effet, à l’entrée, dix inspecteurs ont jugé ce critère. Six l’ont qualifié de « moyen », trois de « bon » et un de « mauvais ». À la sortie, les inspecteurs l’ont renseigné par deux fois et deux l’ont jugé « moyen » et un « très bon ». S’agissant de l’avis des enseignants sur leur propre pratique du français, à l’entrée, neuf considéraient avoir un niveau moyen et les autres relativement bon. À la sortie, six considéraient avoir un niveau à améliorer. Les deux autres, très satisfaits attendaient de la formation IFADEM une amélioration de la qualité d’apprentissage du français. Tableau n° 3 : Brèves présentations des enseignants à l'entrée et à la sortie de la formation  Le tableau 4, quant à lui, propose une synthèse de l’évolution des pratiques d’enseignement avant et après la formation. Celle-ci est positive pour la plupart d’entre elles ; choisir la séance en cohérence avec la progression annuelle, rendre les objectifs clairement identifiables, faire le bilan à la fin de la séance, encourager toujours ou souvent le partage des idées entre élèves, gérer l’espace, la voix, les gestes de façon pertinente, formuler clairement les consignes ou encore, articuler plusieurs compétences.  Tableau n° 4 : Evolution des pratiques d'enseignement avant et après la formation  Enfin, le tableau 5 vise à comparer un échantillon de deux enseignants. Cette comparaison est fondée sur une première observation de leurs pratiques avant qu’ils n’aient été formés puis sur une seconde qui s’est déroulée à l’issue de la formation IFADEM. Tableau n° 5 : Evolution de deux enseignants avant et après la formation  Si le sondage a permis de montrer, très clairement, une évolution de la très grande majorité des compétences des enseignants, il n’en va pas de même pour l’observation pour deux raisons fondamentales :  les observations ont été faites sur dix-sept enseignants à l’entrée et huit à la sortie de la formation ; seuls deux enseignants sur huit faisaient partie de l’échantillon de départ. Ce nombre ne permet pas de voir une évolution dans son ensemble.  En effet, pour ces deux enseignants, nous avons des évolutions différentes certainement dues au fait que les inspecteurs qui les ont observés n’étaient pas les mêmes pour chaque enseignant à l’entrée et à la sortie de la formation.  Conclusion  L’objet de notre contribution était de montrer l’efficacité du dispositif de formation à distance IFADEM. Nous avons pu constater que la formation avait permis une hausse des proportions de bonnes réponses et que les deux outils d’évaluation étaient complémentaires. Néanmoins, des modifications marginales mais nécessaires permettront une meilleure utilisation et analyse de la formation (ex : reformulation de certaines questions, ajout ou suppression d’items, etc.).  Toutefois, l’outil d’observation est plus à nuancer. En effet, premièrement, la déperdition est importante car les observations ont été faites sur dix-sept enseignants à l’entrée et seulement huit à la sortie de la formation. Deuxièmement, seuls deux enseignants sur les huit étaient dans l’échantillon de l’entrée en formation ce qui n’a pas permis d’étudier l’évolution des pratiques d’enseignement entre l’avant et l’après-formation. Troisièmement, ces deux enseignants ont eu des observateurs différents entre l’entrée et la sortie. Ce qui suppose des regards différents et des notations différentes des enseignants. Enfin, les observations ont été effectuées par les inspecteurs « pédagogiques », donc les supérieurs des enseignants ce qui nous laisse supposer que les enseignants ont une pratique plus rigoureuse que traditionnellement lors du passage de ces derniers.  L’analyse des réponses des pratiques enseignantes permet de tirer une série d’indicateurs quantitatifs et qualitatifs précieux pour les concepteurs des programmes de formation ; de même que les données recueillies par l’utilisation de la grille d’observation même si la réflexion nécessite encore de pouvoir analyser un échantillon au sortir de la formation. La formation à distance IFADEM semble avoir contribué à l’amélioration de l’éducation de base pour tous, notamment grâce au développement des compétences des instituteurs en poste, en pédagogie et dans l’enseignement de disciplines linguistiques. Les questions qui ont vu le taux de « bonnes » réponses baisser entre le début et la fin de la formation, sont peu nombreuses et s’expliquent par une vision « rigoriste » de l’apprentissage des langues. En effet, dans les pays d’Afrique du Nord ou subsaharienne, les enseignants restent partisans de la méthode d’apprentissage par « immersion », qui ne laisse pas de place aux approximations ou à l’intégration de la langue maternelle dans la classe.  Le caractère hybride de la formation est sans aucun doute la solution pour ce type de contexte et ce type de public. En effet, cette population enseignante est relativement reculée, elle vit dans des villages qui sont éloignés des villes principales et notamment de la capitale (là où se font traditionnellement les formations). Ainsi plus quatre enseignants sur dix mettent entre un et plusieurs jours pour s’y rendre et sont près de 80 % à utiliser les transports en commun. Un tout présentiel, notamment dans le cas de la formation continue des enseignants, reste trop onéreux pour des pays qui connaissent des difficultés budgétaires et qui voient chaque année la part de la population scolarisée croître, parfois de manière exponentielle.  * Annexe
http://dms.revues.org/1099
10.4000/dms.1099
